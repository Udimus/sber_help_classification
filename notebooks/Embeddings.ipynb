{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача \n",
    "\n",
    "Попробовать эмбеддинги и NN для этой задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import fasttext\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    Activation,\n",
    "    Dropout,\n",
    "    Input,\n",
    "    LSTM,\n",
    "    Reshape,\n",
    "    Lambda,\n",
    "    RepeatVector,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from catboost import CatBoostClassifier\n",
    "import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "from module.prepare_data import load_dataset, Preprocessor\n",
    "from module.model import (\n",
    "    get_cb_pipeline,\n",
    "    TEXT_PROCESSING,\n",
    "    save_pipeline,\n",
    "    load_pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 35\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '../data/test.csv'\n",
    "train_path = '../data/short_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(train_path)\n",
    "test_df = load_dataset(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стемминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_texts = preprocessor.transform(df[['text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = '../data/short_train_corpus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ''.join([text + '\\n' for text in stemmed_texts.values.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "дума сто извин всетак дава подтягива крутан заставля стыд сво способн\n",
      "вызов нативн код банальн шифрован ещ\n",
      "стран топ стоматолог 200 300к \\на аналитик 170\n",
      "плакат описыва ситуац стран давн хорош предлог\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(corpus_path, 'w') as f:\n",
    "    f.write(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 s, sys: 357 ms, total: 26.3 s\n",
      "Wall time: 3.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_skipgram = fasttext.train_unsupervised(corpus_path, model='skipgram', ws=7, minCount=10, dim=emb_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простая нейронка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сперва воспользуемся возможностью Fasttext'а отдавать векторы для целых наборов слов и попробуем простую сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберём сетку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_model(input_size, output_size):\n",
    "    input_values = Input(shape=(input_size,))\n",
    "    input_values_normed = BatchNormalization()(input_values)\n",
    "    first_layer_values = Dense(\n",
    "        50,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-4),\n",
    "        activity_regularizer=regularizers.l2(1e-4)\n",
    "    )(input_values_normed)\n",
    "    first_layer_values_normed = BatchNormalization()(first_layer_values)\n",
    "    output_values = Dense(\n",
    "        output_size,\n",
    "        activation='softmax',\n",
    "        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-3),\n",
    "        bias_regularizer=regularizers.l2(1e-4),\n",
    "        activity_regularizer=regularizers.l2(1e-4)\n",
    "    )(first_layer_values_normed)\n",
    "    model = Model(inputs=input_values, outputs=output_values)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = get_dense_model(emb_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                15050     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 16,552\n",
      "Trainable params: 15,852\n",
      "Non-trainable params: 700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим входные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_vectors = []\n",
    "\n",
    "for stemmed_text in stemmed_texts.values.ravel():\n",
    "    ft_vectors.append(model_skipgram.get_sentence_vector(stemmed_text).reshape(1,-1))\n",
    "    \n",
    "ft_vectors = np.concatenate(ft_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислять ROC-AUC имеет смысл в конце итерации и на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/udimus/env/sber_help_task/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49275cbe25ce4f27bbc9c578ddda9593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8007480482148107\n",
      "0.7740444379190525\n",
      "0.8101344430733993\n",
      "0.7751595162711438\n",
      "0.776902614304189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "for train_index, test_index in tqdm.tqdm_notebook(cv.split(ft_vectors)):\n",
    "    ft_vectors_train = ft_vectors[train_index]\n",
    "    labels_train = df['label'][train_index]\n",
    "    ft_vectors_test = ft_vectors[test_index]\n",
    "    labels_test = df['label'][test_index]\n",
    "    \n",
    "    dense_model = get_dense_model(emb_size, 2)\n",
    "    opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "    dense_model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=SparseCategoricalCrossentropy()\n",
    "    )\n",
    "\n",
    "    train_history = dense_model.fit(\n",
    "        ft_vectors_train,\n",
    "        labels_train,\n",
    "        epochs=32,\n",
    "        validation_data=(ft_vectors_test, labels_test),\n",
    "        verbose=0,\n",
    "    )\n",
    "    \n",
    "    val_prediction = dense_model.predict(ft_vectors_test)[:,-1]\n",
    "    score = roc_auc_score(labels_test, val_prediction)\n",
    "    print(score)\n",
    "    cv_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7873978119565191"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество даже хуже, чем у бейзлайна. Ох уж эти сетки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем отдавать те же векторы от целых сообщений как признаки градиентному бустингу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CatBoostClassifier(iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:  1.4min remaining:  2.0min\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(\n",
    "    cb,\n",
    "    ft_vectors,\n",
    "    df['label'],\n",
    "    cv=cv,\n",
    "    n_jobs=5,\n",
    "    scoring='roc_auc',\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78788774, 0.78465023, 0.77336346, 0.79729041, 0.79530149])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7876986669994883"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мда, похоже, векторные представления для всего текста разом получаются так себе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext + RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного поиграем с параметрами, чтобы получить визуально \"хорошие\" представления."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = '../data/short_train_corpus.txt'\n",
    "\n",
    "preprocessor = Preprocessor('text')\n",
    "stemmed_texts = preprocessor.transform(df[['text']])\n",
    "\n",
    "corpus = ''.join([text + '\\n' for text in stemmed_texts.values.ravel()])\n",
    "with open(corpus_path, 'w') as f:\n",
    "    f.write(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 s, sys: 186 ms, total: 40.2 s\n",
      "Wall time: 4.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_skipgram = fasttext.train_unsupervised(\n",
    "    corpus_path,\n",
    "    model='skipgram',\n",
    "    ws=7,\n",
    "    minCount=5,\n",
    "    epoch=16,\n",
    "    dim=emb_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, какие слова находятся поблизости в словаре Fasttext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3422"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_skipgram.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastTextNearestNeighbours:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.words = model.get_words()\n",
    "        self.matrix = np.concatenate([model[word].reshape(1, -1) for word in self.words], axis=0)\n",
    "        \n",
    "    def find_neighbours_for_vector(self, vector, n_closest=10, return_dist=False):\n",
    "        sims = cosine_similarity(vector.reshape(1, -1), self.matrix).ravel()\n",
    "        word_sims = pd.Series(sims, index=self.words).sort_values(ascending=False)\n",
    "        if return_dist:\n",
    "            return list(word_sims.head(n_closest).iteritems())\n",
    "        return list(word_sims.head(n_closest).index)\n",
    "    \n",
    "    def find_neighbours_for_word(self, word, n_closest=10, return_dist=False):\n",
    "        vector = self.model.get_word_vector(word.lower())\n",
    "        return self.find_neighbours_for_vector(vector, n_closest, return_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_nn = FastTextNearestNeighbours(model_skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым будет идти само слово, если оно есть в словаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "питон\n",
      "[('питон', 0.9999998807907104), ('пайтон', 0.7453288435935974), ('питоновск', 0.7091163992881775), ('пит', 0.6992481350898743), ('андроид', 0.6831347942352295), ('пхп', 0.6695178747177124), ('java', 0.640518307685852), ('си', 0.6400296092033386), ('шарп', 0.6356163024902344), ('php', 0.6266341209411621)]\n",
      "python\n",
      "[('python', 0.9999999403953552), ('c++', 0.7461944818496704), ('py', 0.7144225835800171), ('ini', 0.7013016939163208), ('qt', 0.6961019039154053), ('pyqt', 0.6840329170227051), ('core', 0.6818640232086182), ('are', 0.6694841384887695), ('do', 0.6583818197250366), ('on', 0.6550504565238953)]\n",
      "kaggle\n",
      "[('kaggle', 1.0), ('дс', 0.800108015537262), ('сша', 0.796253502368927), ('европ', 0.7941358089447021), ('атмосфер', 0.7906355857849121), ('дэн', 0.7809733748435974), ('мероприят', 0.7754135131835938), ('24', 0.7699340581893921), ('зп', 0.7636337876319885), ('н', 0.7460345029830933)]\n",
      "кагл\n",
      "[('кагл', 1.0), ('каггл', 0.7552411556243896), ('медальк', 0.7241818904876709), ('ка', 0.6837859153747559), ('картинк', 0.6606423854827881), ('топов', 0.6568261384963989), ('карточк', 0.6563685536384583), ('картинок', 0.6531928777694702), ('мастер', 0.6255955696105957), ('рейтинг', 0.6250377893447876)]\n",
      "докер\n",
      "[('докер', 0.9999997615814209), ('ci', 0.7269625663757324), ('кэш', 0.7172026634216309), ('апач', 0.706761360168457), ('uwsgi', 0.6801703572273254), ('депло', 0.6654138565063477), ('контейнер', 0.6559836268424988), ('док', 0.6549454927444458), ('драйвер', 0.6482937932014465), ('вебхук', 0.6460589170455933)]\n",
      "docker\n",
      "[('docker', 0.9999998807907104), ('do', 0.9029439687728882), ('app', 0.8798818588256836), ('use', 0.8720058798789978), ('which', 0.8618715405464172), ('make', 0.858479380607605), ('system', 0.8541972041130066), ('build', 0.8536450862884521), ('write', 0.8448730707168579), ('shell', 0.8441877365112305)]\n",
      "ml\n",
      "[('ml', 0.9999998807907104), ('azure', 0.6947385668754578), ('sas', 0.6674651503562927), ('учат', 0.6548475027084351), ('гур', 0.6322174072265625), ('анекдот', 0.6265633702278137), ('accuracy', 0.6260521411895752), ('пиар', 0.6239192485809326), ('реклам', 0.6209386587142944), ('хайп', 0.6122514009475708)]\n",
      "шад\n",
      "[('шад', 1.0), ('вшэ', 0.8777120113372803), ('мфти', 0.8358417749404907), ('ад', 0.770263671875), ('mail.ru', 0.7273023128509521), ('егэ', 0.7136592268943787), ('атмосфер', 0.6964940428733826), ('дс', 0.6910212635993958), ('пойдут', 0.6766103506088257), ('ру', 0.6745118498802185)]\n",
      "import\n",
      "[('import', 1.0), ('\\\\nfrom', 0.888373076915741), ('port', 0.8704907298088074), ('as', 0.8643783330917358), ('from', 0.8436957597732544), ('numpy', 0.8331342339515686), ('itertools', 0.7805248498916626), ('start', 0.7611838579177856), ('lxml', 0.7598108053207397), ('zn', 0.7538303732872009)]\n",
      "def\n",
      "[('def', 1.0000001192092896), ('self', 0.9484661817550659), ('\\\\n\\\\nclass', 0.9468328952789307), ('__init__', 0.9399624466896057), ('pass\\\\n', 0.9155818223953247), ('1\\\\n', 0.9034254550933838), ('\\\\ndef', 0.8952845335006714), ('token', 0.8849160671234131), ('password', 0.8846609592437744), ('create', 0.8842325210571289)]\n",
      "функция\n",
      "[('функц', 0.9369852542877197), ('функциона', 0.9297603368759155), ('вызов', 0.7356364130973816), ('многопоточн', 0.7338587641716003), ('выз', 0.7124459147453308), ('кеш', 0.7003477215766907), ('экземпляр', 0.6941604614257812), ('декодер', 0.693340539932251), ('механизм', 0.6914629340171814), ('избежа', 0.6866481304168701)]\n",
      "конкурс\n",
      "[('конкурс', 0.9999998807907104), ('кеггл', 0.7098491191864014), ('accuracy', 0.6996273398399353), ('уйт', 0.6619725823402405), ('каггл', 0.6507816314697266), ('корреляц', 0.6425124406814575), ('участв', 0.6373007893562317), ('конц', 0.6171485781669617), ('организатор', 0.6141777038574219), ('паца', 0.6124083995819092)]\n",
      "топ\n",
      "[('топ', 1.0), ('топ-1', 0.8057985305786133), ('топов', 0.7171726226806641), ('топ10', 0.666155993938446), ('акк', 0.6432812809944153), ('ах', 0.6289343237876892), ('толка', 0.6282570362091064), ('оффтоп', 0.6121547222137451), ('0.6', 0.6097925901412964), ('уйт', 0.6090761423110962)]\n",
      "код\n",
      "[('код', 1.0), ('косяк', 0.6884747743606567), ('ко', 0.626573383808136), ('кодировк', 0.5885584354400635), ('копир', 0.5859348773956299), ('костыл', 0.5822170972824097), ('костыльн', 0.580407977104187), ('корк', 0.5741004943847656), ('коп', 0.5720674991607666), ('кое-чт', 0.5642892718315125)]\n",
      "модел\n",
      "[('модел', 1.0), ('модельк', 0.7378860712051392), ('0.51', 0.6783891916275024), ('логлосс', 0.6763653755187988), ('кроссвалидац', 0.664791464805603), ('валидир', 0.653823733329773), ('0.53', 0.6507261395454407), ('0.54', 0.649384617805481), ('кроссва', 0.6473199725151062), ('логистическ', 0.6414682865142822)]\n",
      "тюн\n",
      "[('тюн', 1.0), ('лгбм', 0.8085622787475586), ('0.53', 0.791122317314148), ('0.3', 0.7851024270057678), ('0.51', 0.7846237421035767), ('ансамбл', 0.779338538646698), ('лайтгбм', 0.7789970636367798), ('0.54', 0.7711986303329468), ('бленд', 0.7674969434738159), ('std', 0.7670096158981323)]\n"
     ]
    }
   ],
   "source": [
    "test_words = [\n",
    "    'питон',\n",
    "    'python',\n",
    "    'kaggle',\n",
    "    'кагл',\n",
    "    'докер',\n",
    "    'docker',\n",
    "    'ml',\n",
    "    'шад',\n",
    "    'import',\n",
    "    'def',\n",
    "    'функция',\n",
    "    'конкурс',\n",
    "    'топ',\n",
    "    'код',\n",
    "    'модел',\n",
    "    'тюн',\n",
    "]\n",
    "\n",
    "for word in test_words:\n",
    "    print(word)\n",
    "    print(fasttext_nn.find_neighbours_for_word(word, n_closest=10, return_dist=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка входных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы не можем просто так запихнуть векторы в embedding-слой -- потому что мы не знаем заранее, какие слова у нас будут. И так мы потеряем мощь Fasttext'а. Так что входом в нашу сетку будут уже представления.\n",
    "\n",
    "Далее, тексты имеют разные длины, чтобы их лучше обрабатывать батчами -- надо их привести к одному размеру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11163.000000\n",
       "mean        10.046224\n",
       "std          8.535108\n",
       "min          0.000000\n",
       "50%          8.000000\n",
       "90%         17.000000\n",
       "95%         23.000000\n",
       "99%         42.000000\n",
       "max        247.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_texts.apply(lambda x: len(x['text'].split()), axis=1).describe(percentiles=[0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Окей, обрежем предложения до 42-х первых слов, более короткие -- заполним нулевыми векторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_matrix(text, model_skipgram, max_words=max_words):\n",
    "    words = (text.split() + ['' for _ in range(max_words)])[:max_words]\n",
    "    words_vectors = [model_skipgram[word].reshape(1, -1) for word in words]\n",
    "    return np.concatenate(words_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([x[np.newaxis,:,:] for\n",
    "                   x in stemmed_texts['text'].apply(lambda x:\n",
    "                                                 text_to_matrix(x, model_skipgram))],\n",
    "                   axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11163, 42, 128)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_model(emb_size, max_len, output_size=2):\n",
    "    input_data = Input(shape=(max_len, emb_size))\n",
    "    first_lstm_values = LSTM(units=64, return_sequences=True)(input_data)\n",
    "    first_dropout_values = Dropout(0.5)(first_lstm_values)\n",
    "    second_lstm_values = LSTM(units=64, return_sequences=False)(first_dropout_values)\n",
    "    second_dropout_values = Dropout(0.5)(second_lstm_values)\n",
    "    dense_values = Dense(units=output_size)(second_dropout_values)\n",
    "    output = Activation('softmax')(dense_values)\n",
    "    model = Model(inputs=input_data, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = get_rnn_model(emb_size, max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        (None, 42, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_59 (LSTM)               (None, 42, 64)            49408     \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 42, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_60 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 82,562\n",
      "Trainable params: 82,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/udimus/env/sber_help_task/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa81fb1e81a4cd8bd868be4a8aba7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8467583216280665\n",
      "0.800916817566355\n",
      "0.8296859500133074\n",
      "0.8201560951836897\n",
      "0.8258270990554455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "\n",
    "for train_index, test_index in tqdm.tqdm_notebook(cv.split(ft_vectors)):\n",
    "    X_train = X[train_index]\n",
    "    labels_train = df['label'][train_index]\n",
    "    X_test = X[test_index]\n",
    "    labels_test = df['label'][test_index]\n",
    "    \n",
    "    rnn_model = get_rnn_model(emb_size, max_words)\n",
    "    rnn_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=SparseCategoricalCrossentropy()\n",
    "    )\n",
    "\n",
    "    train_history = rnn_model.fit(\n",
    "        X_train,\n",
    "        labels_train,\n",
    "        epochs=32,\n",
    "        validation_data=(X_test, labels_test),\n",
    "        verbose=0,\n",
    "    )\n",
    "    \n",
    "    val_prediction = rnn_model.predict(X_test)[:,-1]\n",
    "    score = roc_auc_score(labels_test, val_prediction)\n",
    "    print(score)\n",
    "    cv_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8246688566893727"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало лучше бейзлайна, но качество очень нестабильное. Конечно, можно перебирать параметры... Но лучше вернуться к катбусту)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sber_help_task",
   "language": "python",
   "name": "sber_help_task"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
